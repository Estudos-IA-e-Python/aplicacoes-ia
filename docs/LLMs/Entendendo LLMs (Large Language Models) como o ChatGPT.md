# 📘 Estudo – Entendendo LLMs (Large Language Models) como o ChatGPT

---
[Deep Dive into LLMs like ChatGPT - Andrej Karpathy](https://www.youtube.com/watch?v=7xTGNNLPyMI)


## 🔹 1. O que são LLMs?

**Large Language Models (LLMs)** são redes neurais treinadas em bilhões de palavras para reconhecer padrões da linguagem e **gerar texto coerente**.  
Eles não "entendem" como humanos, mas **aprendem estatísticas da linguagem**.

- **Analogia**: imagine que você leu milhões de livros, artigos e conversas. Ao escrever, você prevê intuitivamente a próxima palavra com base em tudo o que já leu.  
→ É exatamente isso que o LLM faz.

- **Arquitetura base**: utilizam **Transformers** (artigo *Attention is All You Need*, 2017).  
Esse modelo trouxe o conceito de **atenção**, permitindo que o LLM entenda contexto em longas sequências.

---

## 🔹 2. Como funcionam?

1. **Tokenização**  
   O texto é dividido em **tokens** (pedaços menores, como sílabas ou palavras).  
   Exemplo: `"QA é incrível"` → `[QA] [é] [in] [crível]`.

2. **Embeddings**  
   Cada token é convertido em um **vetor numérico** em um espaço de alta dimensão.  
   Palavras semelhantes ficam próximas nesse espaço (ex.: “rei” e “rainha”).

3. **Self-Attention**  
   O modelo analisa **cada token em relação a todos os outros** da sequência.  
   Isso dá “memória contextual”: entende que *"banco"* pode significar **instituição financeira** ou **assento**, dependendo da frase.

4. **Decodificação (saída)**  
   O modelo calcula a **probabilidade do próximo token** e escolhe o mais adequado.  
   Repete até formar a resposta completa.

---

## 🔹 3. Treinamento

- **Pré-treinamento**  
  O modelo é treinado em grandes volumes de texto (livros, artigos, código).  
  Aprende **estatísticas gerais da linguagem**.

- **Fine-tuning (ajuste fino)**  
  O modelo é adaptado a contextos específicos.  
  Exemplo: atendimento ao cliente → *chatbot de suporte*.

- **RLHF (Reinforcement Learning with Human Feedback)**  
  Pessoas avaliam respostas → o modelo aprende quais são melhores.  
  Ajuda a reduzir erros e respostas tóxicas.

---

## 🔹 4. Limitações

- **Alucinações**  
  Podem inventar fatos, já que geram probabilidades, não verdades.

- **Viés**  
  Refletem preconceitos e distorções presentes nos dados de treino.

- **Janela de contexto**  
  Só conseguem “lembrar” de um número limitado de tokens.  
  (Ex.: GPT-3.5 ~4k tokens, GPT-4 até 128k).

- **Custo computacional**  
  Treinamento exige GPUs poderosas e datasets gigantes.  
  Só grandes empresas conseguem treinar do zero.

---

## 🔹 5. Aplicações

- **Chatbots e agentes de suporte** → FAQ, atendimento em sites.  
- **Auxílio à programação** → GitHub Copilot sugere código em tempo real.  
- **Geração de conteúdo** → posts, relatórios, resumos, roteiros.  
- **Análise de dados e relatórios** → identificar padrões em grandes volumes de logs.  
- **QA e desenvolvimento**  
  - Gerar **casos de teste** automaticamente.  
  - Fazer **análise de logs** para prever falhas.  
  - **Classificar bugs** por severidade.  
  - Criar **agentes de QA inteligentes**.

---

## 🎯 Resumindo

- **LLMs** = modelos que **preveem a próxima palavra** com base em grandes volumes de texto.  
- Funcionam com **tokens, embeddings e atenção**.  
- São treinados em 2 fases (**pré-treinamento + ajuste fino**).  
- Têm limitações (alucinações, viés, contexto limitado).  
- Podem revolucionar áreas como **QA, desenvolvimento e automação de testes**.

---

> "Os LLMs não pensam como humanos. Eles reconhecem padrões da linguagem e, a partir disso, geram respostas com base em probabilidades."

## 📂 Links Importantes
- 📄 Versão original em inglês (NIPS 2017): [Attention Is All You Need (PDF)](https://arxiv.org/pdf/1706.03762.pdf)  